{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Football Logos Classification by League\n",
    "\n",
    "**Objective:** Classify football team logos into their respective European leagues.\n",
    "\n",
    "**Dataset:** 605 logos from 26 European leagues.\n",
    "\n",
    "**Models:** Custom CNN baseline and ResNet18 transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.append('..')\n\nimport torch\nimport matplotlib.pyplot as plt\n\nfrom src.dataset import get_dataloaders\nfrom src.models import CustomCNN, get_resnet18\nfrom src.train import train_model\nfrom src.evaluate import evaluate_model, plot_confusion_matrix, plot_training_history\nfrom src.utils import predict_from_dataset, visualize_prediction_from_dataset, visualize_dataset_samples\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {DEVICE}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader, val_loader, test_loader, class_names = get_dataloaders(\n",
    "    DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    val_split=0.15,\n",
    "    test_split=0.15\n",
    ")\n",
    "\n",
    "print(f\"Number of classes (leagues): {len(class_names)}\")\n",
    "print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation samples: {len(val_loader.dataset)}\")\n",
    "print(f\"Test samples: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Leagues in dataset:\")\n",
    "for i, league in enumerate(class_names, 1):\n",
    "    print(f\"{i:2d}. {league}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset_samples(train_loader.dataset.dataset, class_names, n_samples=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 1: Custom CNN (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = CustomCNN(num_classes=len(class_names))\n",
    "print(\"Model 1: Custom CNN\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model1.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = train_model(\n",
    "    model1,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=20,\n",
    "    lr=0.001,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 2: ResNet18 (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = get_resnet18(num_classes=len(class_names), pretrained=True)\n",
    "print(\"Model 2: ResNet18 with ImageNet pretrained weights\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model2.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = train_model(\n",
    "    model2,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=15,\n",
    "    lr=0.0001,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"MODEL 1: Custom CNN\")\n",
    "print(\"=\" * 50)\n",
    "results1 = evaluate_model(model1, test_loader, class_names, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MODEL 2: ResNet18\")\n",
    "print(\"=\" * 50)\n",
    "results2 = evaluate_model(model2, test_loader, class_names, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Custom CNN Accuracy: {results1['accuracy']:.2f}%\")\n",
    "print(f\"ResNet18 Accuracy: {results2['accuracy']:.2f}%\")\n",
    "print(f\"Improvement: {results2['accuracy'] - results1['accuracy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = results2 if results2['accuracy'] > results1['accuracy'] else results1\n",
    "plot_confusion_matrix(\n",
    "    best_results['labels'],\n",
    "    best_results['predictions'],\n",
    "    class_names,\n",
    "    figsize=(14, 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Test Predictions on Random Samples"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import random\n\nbest_model = model2 if results2['accuracy'] > results1['accuracy'] else model1\ntest_dataset = test_loader.dataset.dataset\n\nrandom_idx = random.randint(0, len(test_dataset) - 1)\n\npredictions, true_label, image = predict_from_dataset(\n    test_dataset,\n    best_model,\n    class_names,\n    random_idx,\n    device=DEVICE,\n    top_k=5\n)\n\nprint(f\"True Label: {true_label}\")\nprint(\"\\nTop 5 predictions:\")\nfor i, (league, prob) in enumerate(predictions, 1):\n    print(f\"{i}. {league}: {prob:.2f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "visualize_prediction_from_dataset(image, predictions[:3], true_label)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '../models/best_model.pth'\n",
    "torch.save(best_model.state_dict(), MODEL_PATH)\n",
    "print(f\"Best model saved to {MODEL_PATH}\")\n",
    "print(f\"Final test accuracy: {max(results1['accuracy'], results2['accuracy']):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}